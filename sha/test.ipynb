{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f17f8657",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f831fc05",
   "metadata": {},
   "source": [
    "# plan\n",
    "1. Data Preprocessing \n",
    "    - encoding Social_Responsiveness_Scale scaling\n",
    "    ,Speech Delay/Language Disorder, Learning disorder, Genetic_Disorders,\n",
    "    Depression, Global developmental delay/intellectual disability, Social/Behavioural Issues,\n",
    "    Childhood Autism Rating Scale, Anxiety_disorder, Sex, Ethnicity, Jaundice, Family_mem_with_ASD,\n",
    "    Who_completed_the_test, ASD_traits\n",
    "    \n",
    "    - Null values handling on Social_Responsiveness_Scale,Qchat_10_Score, Depression, Social/Behavioural Issues\n",
    "    \n",
    "2. Enter the ML phase and make predictions\n",
    "3. select the best model\n",
    "4. XAI\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19773969",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Read the Dataset\n",
    "df = pd.read_csv('data_csv.csv')\n",
    "df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d74f2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply Pandas Profiling\n",
    "from ydata_profiling import ProfileReport\n",
    "prof = ProfileReport(df)\n",
    "prof.to_file(output_file = 'ASD.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b22f1f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "IMAGES_PATH = Path() / \"images\" / \"Data Preprocessing\"\n",
    "IMAGES_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = IMAGES_PATH / f\"{fig_id}.{fig_extension}\"\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e672b667",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# extra code â€“ the next 5 lines define the default font sizes\n",
    "plt.rc('font', size=14)\n",
    "plt.rc('axes', labelsize=14, titlesize=14)\n",
    "plt.rc('legend', fontsize=14)\n",
    "plt.rc('xtick', labelsize=10)\n",
    "plt.rc('ytick', labelsize=10)\n",
    "\n",
    "df.hist(bins=50, figsize=(12, 8))\n",
    "save_fig(\"attribute_histogram_plots\")  # extra code\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca3b11e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf644d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3acdb156",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d8156b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "# Define the categorical columns you want to label encode\n",
    "categorical_columns = ['Speech Delay/Language Disorder', 'Learning disorder', 'Genetic_Disorders', 'Depression', \n",
    "                       'Global developmental delay/intellectual disability',\n",
    "                       'Social/Behavioural Issues', 'Childhood Autism Rating Scale', 'Anxiety_disorder', \n",
    "                       'Sex', 'Ethnicity', 'Jaundice', 'Family_mem_with_ASD', 'Who_completed_the_test', 'ASD_traits']\n",
    "\n",
    "for column in categorical_columns:\n",
    "    labelencoder = LabelEncoder()\n",
    "    df[column] = labelencoder.fit_transform(df[column])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb0196d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe1d2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#handling null values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2071d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(axis=0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc345d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31df8679",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16313b05",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b8402b",
   "metadata": {},
   "source": [
    "# Preprocessed Dataset Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8917b85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17a0247",
   "metadata": {},
   "outputs": [],
   "source": [
    "compression_opts = dict(method='zip',\n",
    "                        archive_name='preprocessed.csv')  \n",
    "df.to_csv('out.zip', index=False,\n",
    "          compression=compression_opts)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46210a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "folder_path = Path('C:/Shanila/CSE/cse445/final_project/git_project/Machine_Learning_Project/sha')\n",
    "filepath = folder_path / 'preprocessed.csv'\n",
    "\n",
    "folder_path.mkdir(parents=True, exist_ok=True)\n",
    "df.to_csv(filepath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e90d7b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    ">>> import os  \n",
    ">>> os.makedirs('folder/subfolder', exist_ok=True)  \n",
    ">>> df.to_csv('folder/subfolder/out.csv')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db221dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "folder_path = 'C:/Shanila/CSE/cse445/final_project/git_project/Machine_Learning_Project/sha'\n",
    "os.makedirs(folder_path, exist_ok=True)\n",
    "\n",
    "df.to_csv(os.path.join(folder_path, 'preprocessed.csv'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb6cd98",
   "metadata": {},
   "source": [
    "# Entering the ML Phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48486d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=[\"Learning disorder\", \"CASE_NO_PATIENT'S\"], axis=1)\n",
    "y= df['Learning disorder']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13eced40",
   "metadata": {},
   "source": [
    "# Splitting Train and Test set in 80-20 ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211d2060",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.20,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVE TRAIN SET AND TEST SET\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Specify the folder paths C:/Shanila/CSE/cse445/final_project/git_project/Machine_Learning_Project/sha\n",
    "train_folder = \"C:\\\\Shanila\\\\CSE\\\\cse445\\\\final_project\\\\git_project\\\\Machine_Learning_Project\\\\sha\\\\train\"\n",
    "test_folder = \"C:\\\\Shanila\\\\CSE\\\\cse445\\\\final_project\\\\git_project\\\\Machine_Learning_project\\\\sha\\\\test\"\n",
    "\n",
    "# Create the folders if they don't exist\n",
    "os.makedirs(train_folder, exist_ok=True)\n",
    "os.makedirs(test_folder, exist_ok=True)\n",
    "\n",
    "# Save X_train and y_train as CSV files in the \"train\" folder\n",
    "train_data = pd.concat([X_train, y_train], axis=1)\n",
    "train_data.to_csv(os.path.join(train_folder, \"train_data.csv\"), index=False)\n",
    "\n",
    "# Save X_test and y_test as CSV files in the \"test\" folder\n",
    "test_data = pd.concat([X_test, y_test], axis=1)\n",
    "test_data.to_csv(os.path.join(test_folder, \"test_data.csv\"), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb5035ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing ML Algorithms to test\n",
    "\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82010134",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.metrics.plot import confusion_matrix\n",
    "#import error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7019b916",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def Results(clf):\n",
    "    print(clf)\n",
    "    clf.fit(X_train, y_train)\n",
    "    predictions = clf.predict(X_test)\n",
    "    print('Train Accuracy', accuracy_score(y_train, clf.predict(X_train)))\n",
    "    print('Test Accuracy', accuracy_score(y_test, predictions))\n",
    "    print(confusion_matrix(y_test, predictions))\n",
    "    print(classification_report(y_test, predictions))\n",
    "    #also pretty confusion matrix\n",
    "    print(\"-\" * 60)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531451d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors = 5)\n",
    "knn2 = KNeighborsClassifier(n_neighbors = 15)\n",
    "dt1 = DecisionTreeClassifier() #Gini\n",
    "dt2 = DecisionTreeClassifier(criterion = 'entropy') #entropy\n",
    "rf = RandomForestClassifier()\n",
    "nb = GaussianNB()\n",
    "lr = LinearRegression()\n",
    "lor = LogisticRegression()\n",
    "dummy = DummyClassifier(strategy = \"most_frequent\")\n",
    "dummy.fit(X, y)\n",
    "\n",
    "classifiers = [dummy,  dt1, dt2, rf, knn, knn2, nb, lr, lor]\n",
    "\n",
    "\n",
    "for clf in classifiers:\n",
    "    if clf in [lr, lor]:\n",
    "        # For Linear Regression and Logistic Regression\n",
    "        print(clf)\n",
    "        clf.fit(X_train, y_train)\n",
    "        predictions = clf.predict(X_test)\n",
    "        print('Train Accuracy', clf.score(X_train, y_train))\n",
    "        print('Test Accuracy', clf.score(X_test, y_test))\n",
    "        #print('Log Loss:', log_loss(y_test, clf.predict_proba(X_test)))\n",
    "        # Additional regression-specific evaluation metrics can be added here\n",
    "        print(\"-\" * 60)\n",
    "    else:\n",
    "        Results(clf)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, mean_squared_error\n",
    "\n",
    "def Results(clf, is_regression=False):\n",
    "    print(clf)\n",
    "    clf.fit(X_train, y_train)\n",
    "    predictions = clf.predict(X_test)\n",
    "    \n",
    "    if is_regression:\n",
    "        # Regression-specific evaluation metrics\n",
    "        train_accuracy = clf.score(X_train, y_train)\n",
    "        test_accuracy = clf.score(X_test, y_test)\n",
    "        mse = mean_squared_error(y_test, predictions)\n",
    "        print(f'Train Accuracy: {train_accuracy:.2f}')\n",
    "        print(f'Test Accuracy: {test_accuracy:.2f}')\n",
    "        print(f'Mean Squared Error: {mse:.2f}')\n",
    "    else:\n",
    "        # Classification-specific evaluation metrics\n",
    "        train_accuracy = accuracy_score(y_train, clf.predict(X_train))\n",
    "        test_accuracy = accuracy_score(y_test, predictions)\n",
    "        classification_report_str = classification_report(y_test, predictions)\n",
    "        print(f'Train Accuracy: {train_accuracy:.2f}')\n",
    "        print(f'Test Accuracy: {test_accuracy:.2f}')\n",
    "        print('Classification Report:\\n', classification_report_str)\n",
    "    \n",
    "    print(\"-\" * 60)\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn2 = KNeighborsClassifier(n_neighbors=15)\n",
    "dt1 = DecisionTreeClassifier()  # Gini\n",
    "dt2 = DecisionTreeClassifier(criterion='entropy')  # entropy\n",
    "rf = RandomForestClassifier()\n",
    "nb = GaussianNB()\n",
    "lr = LinearRegression()\n",
    "lor = LogisticRegression()\n",
    "dummy = DummyClassifier(strategy=\"most_frequent\")\n",
    "dummy.fit(X, y)\n",
    "\n",
    "classifiers = [dummy, dt1, dt2, rf, knn, knn2, nb, lr, lor]\n",
    "\n",
    "for clf in classifiers:\n",
    "    is_regression = clf in [lr, lor]\n",
    "    Results(clf, is_regression)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # save result in result seperately\n",
    "# also has csv, doc and images png\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "# Define a function to save the results to a text (TXT) file and as a PNG image\n",
    "def save_results_to_files(clf, txt_file_path, png_file_path, X_train, X_test, y_train, y_test):\n",
    "    clf.fit(X_train, y_train)\n",
    "    predictions = clf.predict(X_test)\n",
    "\n",
    "    if hasattr(clf, 'predict_proba'):\n",
    "        # Classification model\n",
    "        train_accuracy = accuracy_score(y_train, clf.predict(X_train))\n",
    "        test_accuracy = accuracy_score(y_test, predictions)\n",
    "        confusion = confusion_matrix(y_test, predictions)\n",
    "        report = classification_report(y_test, predictions, output_dict=True)\n",
    "\n",
    "        # Save results to a text (TXT) file\n",
    "        with open(txt_file_path, 'w') as file:\n",
    "            file.write(f\"Train Accuracy: {train_accuracy*100:.4f}%\\n\")\n",
    "            file.write(f\"Test Accuracy: {test_accuracy*100:.4f}%\\n\")\n",
    "            file.write(\"Confusion Matrix:\\n\")\n",
    "            file.write(str(confusion) + \"\\n\")\n",
    "            file.write(\"Classification Report:\\n\")\n",
    "\n",
    "            # Split the classification report into lines\n",
    "            report_lines = classification_report(y_test, predictions).split('\\n')\n",
    "            for line in report_lines:\n",
    "                # Check if the line is not empty\n",
    "                if line:\n",
    "                    # Split the line into words\n",
    "                    words = line.split()\n",
    "                    # Format precision, recall, f1-score, and support as percentages\n",
    "                    formatted_line = ' '.join([f'{float(word)*100:.4f}%' if '%' in word else word for word in words])\n",
    "                    file.write(formatted_line + '\\n')\n",
    "\n",
    "    else:\n",
    "        # Regression model\n",
    "        train_mse = mean_squared_error(y_train, clf.predict(X_train))\n",
    "        test_mse = mean_squared_error(y_test, predictions)\n",
    "\n",
    "        # Save results to a text (TXT) file\n",
    "        with open(txt_file_path, 'w') as file:\n",
    "            file.write(f\"Train Mean Squared Error: {train_mse:.4f}\\n\")\n",
    "            file.write(f\"Test Mean Squared Error: {test_mse:.4f}\\n\")\n",
    "\n",
    "    # Save the confusion matrix as a PNG image for classification models\n",
    "    if hasattr(clf, 'predict_proba'):\n",
    "        save_confusion_matrix_as_png(confusion, clf, png_file_path)\n",
    "\n",
    "# Function to save the confusion matrix as a PNG image for classification models\n",
    "def save_confusion_matrix_as_png(matrix, clf, png_file_path):\n",
    "    # Create a custom color map with specified colors\n",
    "    colors = ['#B1BCE6', '#B2C8DF', '#C4D7E0', '#EFEFEF']\n",
    "    cmap = LinearSegmentedColormap.from_list('Custom', colors, N=matrix.max() + 1)\n",
    "\n",
    "    # Plot the confusion matrix with the custom color map\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.imshow(matrix, interpolation='nearest', cmap=cmap)\n",
    "    plt.colorbar()\n",
    "\n",
    "    # Add labels to the confusion matrix\n",
    "    for i in range(matrix.shape[0]):\n",
    "        for j in range(matrix.shape[1]):\n",
    "            plt.text(j, i, matrix[i, j], horizontalalignment='center', verticalalignment='center', fontsize=12, color='black')\n",
    "\n",
    "    plt.title(f'Confusion Matrix - {clf}')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "\n",
    "    # Save the confusion matrix as a PNG image\n",
    "    plt.savefig(png_file_path, bbox_inches='tight', dpi=100)\n",
    "    plt.close()\n",
    "\n",
    "# Specify the directory for saving the result files\n",
    "result_directory = \"C:\\\\Shanila\\\\CSE\\\\cse445\\\\final_project\\\\git_project\\\\Machine_Learning_project\\\\sha\\\\result\\\\\"\n",
    "\n",
    "# List of classifiers to evaluate\n",
    "classifiers = [dummy, dt1, dt2, rf, knn, knn2, nb, lr, lor]\n",
    "\n",
    "for clf in classifiers:\n",
    "    # Generate file names based on the classifier's name\n",
    "    classifier_name = clf.__class__.__name__\n",
    "    txt_file_path = os.path.join(result_directory, f\"{classifier_name}_results.txt\")\n",
    "    png_file_path = os.path.join(result_directory, f\"{classifier_name}_confusion_matrix.png\")\n",
    "\n",
    "    # Call the function to save the results and pass X_train, X_test, y_train, and y_test\n",
    "    save_results_to_files(clf, txt_file_path, png_file_path, X_train, X_test, y_train, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bar chart for test and train set\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# List of classifiers (excluding Linear Regression)\n",
    "classifiers = [dummy, dt1, dt2, rf, knn, knn2, nb, lor]\n",
    "\n",
    "# Train and test accuracies for each classifier\n",
    "train_accuracies = [accuracy_score(y_train, clf.predict(X_train)) for clf in classifiers]\n",
    "test_accuracies = [accuracy_score(y_test, clf.predict(X_test)) for clf in classifiers]\n",
    "\n",
    "# Bar positions\n",
    "positions = np.arange(len(classifiers))\n",
    "\n",
    "# Bar height\n",
    "bar_height = 0.35\n",
    "\n",
    "# Bar colors\n",
    "train_colors = ['#7895B2'] * len(classifiers)\n",
    "test_colors = ['#D2DAFF'] * len(classifiers)\n",
    "\n",
    "# Create the horizontal bar chart for train set accuracy\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(positions - bar_height/2, train_accuracies, bar_height, color=train_colors, edgecolor='black', linewidth=0.5, label='Train Set Accuracy')\n",
    "\n",
    "# Create the horizontal bar chart for test set accuracy\n",
    "plt.barh(positions + bar_height/2, test_accuracies, bar_height, color=test_colors, edgecolor='black', linewidth=0.5, label='Test Set Accuracy')\n",
    "\n",
    "# Add accuracy percentages on top of each bar\n",
    "for i in range(len(classifiers)):\n",
    "    plt.text(train_accuracies[i] + 0.005, i - bar_height / 2, f'{train_accuracies[i]*100:.2f}%', color='black', ha='left')\n",
    "    plt.text(test_accuracies[i] + 0.005, i + bar_height / 2, f'{test_accuracies[i]*100:.2f}%', color='black', ha='left')\n",
    "\n",
    "# Set the y-axis labels\n",
    "labels = ['Dummy', 'Decision Tree (Gini)', 'Decision Tree (Entropy)', 'Random Forest', 'K-Nearest Neighbors (k=5)', 'K-Nearest Neighbors (k=15)', 'Naive Bayes', 'Logistic Regression']\n",
    "plt.yticks(positions, labels)\n",
    "\n",
    "# Set the x-axis label\n",
    "plt.xlabel('Accuracy')\n",
    "\n",
    "# Set the chart title\n",
    "plt.title('Classifier Train and Test Set Accuracy')\n",
    "\n",
    "# Set x-axis limits to provide more space for the labels\n",
    "plt.xlim(0, 1.3)\n",
    "\n",
    "# Show the legend\n",
    "plt.legend(loc='best')\n",
    "\n",
    "# Display the plot\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the plot to the specified destination in high definition\n",
    "plot_save_path = \"C:\\\\Shanila\\\\CSE\\\\cse445\\\\final_project\\\\git_project\\\\Machine_Learning_project\\\\sha\\\\result2\\\\classifier_accuracy_horizontal.png\"\n",
    "plt.savefig(plot_save_path, bbox_inches='tight', dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import pandas as pd\n",
    "\n",
    "# Load the training and testing data from CSV files\n",
    "train_data = pd.read_csv(\"C:\\\\Shanila\\\\CSE\\\\cse445\\\\final_project\\\\git_project\\\\Machine_Learning_project\\\\sha\\\\train\\\\train_data.csv\")\n",
    "test_data = pd.read_csv(\"C:\\\\Shanila\\\\CSE\\\\cse445\\\\final_project\\\\git_project\\\\Machine_Learning_project\\\\sha\\\\test\\\\test_data.csv\")\n",
    "\n",
    "# Separate features (X) and target (y) for both training and testing data\n",
    "X_train = train_data.drop(columns=[\"Learning disorder\"])\n",
    "y_train = train_data[\"Learning disorder\"]\n",
    "X_test = test_data.drop(columns=[\"Learning disorder\"])\n",
    "y_test = test_data[\"Learning disorder\"]\n",
    "\n",
    "# Create a dictionary to store results\n",
    "results = {}\n",
    "\n",
    "# Initialize and evaluate different classifiers\n",
    "classifiers = {\n",
    "    \"Dummy Classifier\": DummyClassifier(),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"K-Nearest Neighbors\": KNeighborsClassifier(),\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"Logistic Regression\": LogisticRegression(),\n",
    "    \"Naive Bayes\": GaussianNB()\n",
    "}\n",
    "\n",
    "for name, classifier in classifiers.items():\n",
    "    # Fit the classifier on the training data\n",
    "    classifier.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions on the testing data\n",
    "    predictions = classifier.predict(X_test)\n",
    "    \n",
    "    # Evaluate the classifier and store the results\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    report = classification_report(y_test, predictions)\n",
    "    matrix = confusion_matrix(y_test, predictions)\n",
    "    \n",
    "    results[name] = {\n",
    "        \"Accuracy\": accuracy,\n",
    "        \"Classification Report\": report,\n",
    "        \"Confusion Matrix\": matrix\n",
    "    }\n",
    "\n",
    "# Create a DataFrame from the results dictionary\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Specify the path to save the results as a CSV file\n",
    "results_csv_path = \"C:\\\\Shanila\\\\CSE\\\\cse445\\\\final_project\\\\git_project\\\\Machine_Learning_project\\\\sha\\\\results.csv\"\n",
    "\n",
    "# Save the results as a CSV file\n",
    "results_df.to_csv(results_csv_path, index=False)\n",
    "\n",
    "# Optionally, you can also display the results DataFrame\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "charts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the results from the CSV file\n",
    "results_df = pd.read_csv(\"C:\\\\Shanila\\\\CSE\\\\cse445\\\\final_project\\\\git_project\\\\Machine_Learning_Project\\\\sha\\\\results.csv\")\n",
    "\n",
    "# Define the classifiers and their corresponding accuracies\n",
    "classifiers = results_df.columns\n",
    "accuracies = results_df.loc[0].values.astype(float)  # Convert the values to float\n",
    "\n",
    "# Create a horizontal bar chart\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Create a bar plot with labels\n",
    "bar_positions = np.arange(len(classifiers))\n",
    "bar_colors = ['#7895B2', '#D2DAFF', '#B2C8DF', '#B1BCE6', '#EFEFEF', '#C4D7E0']\n",
    "plt.barh(bar_positions, accuracies, color=bar_colors, edgecolor='black', linewidth=0.5)\n",
    "\n",
    "# Add accuracy percentages on the bars\n",
    "for i, acc in enumerate(accuracies):\n",
    "    plt.text(acc + 0.005, i, f'{acc * 100:.2f}%', color='black', va='center')\n",
    "\n",
    "# Set the y-axis labels\n",
    "plt.yticks(bar_positions, classifiers)\n",
    "\n",
    "# Set the x-axis label\n",
    "plt.xlabel('Accuracy')\n",
    "\n",
    "# Set the chart title\n",
    "plt.title('Classifier Accuracies')\n",
    "\n",
    "# Set x-axis limits to provide more space for the labels\n",
    "plt.xlim(0, 1.3)\n",
    "\n",
    "# Save the bar chart as a PNG\n",
    "bar_chart_save_path = \"C:\\\\Shanila\\\\CSE\\\\cse445\\\\final_project\\\\git_project\\\\Machine_Learning_Project\\\\sha\\\\result2\\\\bar_chart.png\"\n",
    "plt.savefig(bar_chart_save_path, bbox_inches='tight', dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "table NEEDS UPDATING RESULT2.XLSX AND RUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Read the data from the Excel file\n",
    "result2_df = pd.read_excel(\"C:\\\\Shanila\\\\CSE\\\\cse445\\\\final_project\\\\git_project\\\\Machine_Learning_Project\\\\sha\\\\result2.xlsx\")\n",
    "\n",
    "# Create a figure and axis\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "# Create a table with the data from the DataFrame\n",
    "table_data = [result2_df.columns] + result2_df.values.tolist()\n",
    "table = ax.table(cellText=table_data, loc='center', cellLoc='center', colWidths=[0.45]*len(result2_df.columns),\n",
    "                 rowLabels=[\"\"] + list(result2_df[\"Classifier\"]), rowLoc='center')\n",
    "\n",
    "# Increase row height\n",
    "table.scale(1, 2.5)  # You can adjust the scaling factor as needed\n",
    "\n",
    "# Style the table\n",
    "table.auto_set_font_size(False)\n",
    "table.set_fontsize(12)\n",
    "\n",
    "# Hide the axis\n",
    "ax.axis('off')\n",
    "\n",
    "# Save the table as a PNG image\n",
    "table_save_path = \"C:\\\\Shanila\\\\CSE\\\\cse445\\\\final_project\\\\git_project\\\\Machine_Learning_Project\\\\sha\\\\result2\\\\result2_table_wide.png\"\n",
    "plt.savefig(table_save_path, bbox_inches='tight', dpi=300)\n",
    "\n",
    "# Show the table (optional)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f42302c0",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3644c29e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Manual Hyperparameter Tuning\n",
    "model=RandomForestClassifier(n_estimators=300,criterion='entropy',\n",
    "                             max_features='sqrt',min_samples_leaf=10,random_state=100).fit(X_train,y_train)\n",
    "predictions=model.predict(X_test)\n",
    "print(confusion_matrix(y_test,predictions))\n",
    "print(accuracy_score(y_test,predictions))\n",
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d23b6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Manual Hyperparameter Tuning 2\n",
    "model=RandomForestClassifier(n_estimators=500,criterion='gini',\n",
    "                             max_features='sqrt',min_samples_leaf=10,random_state=100).fit(X_train,y_train)\n",
    "predictions=model.predict(X_test)\n",
    "print(confusion_matrix(y_test,predictions))\n",
    "print(accuracy_score(y_test,predictions))\n",
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c8f28b42",
   "metadata": {},
   "source": [
    "##### Randomized Search "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c1c51af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt','log2']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 1000,10)]\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10,14]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4,6,8]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "              'criterion':['entropy','gini']}\n",
    "print(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "089b14a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf=RandomForestClassifier()\n",
    "rf_randomcv=RandomizedSearchCV(estimator=rf,param_distributions=random_grid,n_iter=100,cv=3,verbose=2,\n",
    "                               random_state=100,n_jobs=-1)\n",
    "### fit the randomized model\n",
    "rf_randomcv.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e109e125",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_randomcv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2adba464",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_randomcv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f186f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_randomcv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918c0e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_random_grid=rf_randomcv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "915d96b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "best_random_grid.fit(X_train, y_train)\n",
    "y_pred=best_random_grid.predict(X_test)\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(\"Accuracy Score {}\".format(accuracy_score(y_test,y_pred)))\n",
    "print(\"Classification report: {}\".format(classification_report(y_test,y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd2fa7cb",
   "metadata": {},
   "source": [
    "#### Grid Search "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650fb3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_randomcv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc31ee70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'criterion': [rf_randomcv.best_params_['criterion']],\n",
    "    'max_depth': [rf_randomcv.best_params_['max_depth']],\n",
    "    'max_features': [rf_randomcv.best_params_['max_features']],\n",
    "    'min_samples_leaf': [rf_randomcv.best_params_['min_samples_leaf'], \n",
    "                         rf_randomcv.best_params_['min_samples_leaf']+2, \n",
    "                         rf_randomcv.best_params_['min_samples_leaf'] + 4],\n",
    "    'min_samples_split': [rf_randomcv.best_params_['min_samples_split'] - 2,\n",
    "                          rf_randomcv.best_params_['min_samples_split'] - 1,\n",
    "                          rf_randomcv.best_params_['min_samples_split'], \n",
    "                          rf_randomcv.best_params_['min_samples_split'] +1,\n",
    "                          rf_randomcv.best_params_['min_samples_split'] + 2],\n",
    "    'n_estimators': [rf_randomcv.best_params_['n_estimators'] - 200, rf_randomcv.best_params_['n_estimators'] - 100, \n",
    "                     rf_randomcv.best_params_['n_estimators'], \n",
    "                     rf_randomcv.best_params_['n_estimators'] + 100, rf_randomcv.best_params_['n_estimators'] + 200]\n",
    "}\n",
    "\n",
    "print(param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ed7340",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Your long-running code here\n",
    "#### Fit the grid_search to the data\n",
    "rf=RandomForestClassifier()\n",
    "grid_search=GridSearchCV(estimator=rf,param_grid=param_grid,cv=10,n_jobs=-1,verbose=2)\n",
    "grid_search.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "\n",
    "# Read the data from the text file into a DataFrame\n",
    "df = pd.read_csv(\"C:\\\\Shanila\\\\CSE\\\\cse445\\\\final_project\\\\git_project\\\\Machine_Learning_Project\\\\sha\\\\result3\\\\grid_search_results.txt\", delimiter=\"\\t\", header=0)  # Adjust the delimiter if needed\n",
    "\n",
    "# Sort by mean_test_score in descending order\n",
    "sorted_results = df.sort_values(by='mean_test_score', ascending=False)\n",
    "\n",
    "# The best hyperparameter combination should be in the first row\n",
    "best_hyperparameters = sorted_results.iloc[0]\n",
    "\n",
    "# Extract the best hyperparameters\n",
    "criterion = best_hyperparameters['param_criterion']\n",
    "max_depth = best_hyperparameters['param_max_depth']\n",
    "max_features = best_hyperparameters['param_max_features']\n",
    "min_samples_leaf = best_hyperparameters['param_min_samples_leaf']\n",
    "min_samples_split = best_hyperparameters['param_min_samples_split']\n",
    "n_estimators = best_hyperparameters['param_n_estimators']\n",
    "\n",
    "# Create the best estimator with the best hyperparameters\n",
    "best_estimator = RandomForestClassifier(criterion=criterion, max_depth=max_depth, max_features=max_features, min_samples_leaf=min_samples_leaf, min_samples_split=min_samples_split, n_estimators=n_estimators)\n",
    "\n",
    "# Fit the best estimator on the training data\n",
    "best_estimator.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = best_estimator.predict(X_test)\n",
    "\n",
    "# Print confusion matrix, accuracy score, and classification report\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "\n",
    "# Print the results\n",
    "print(\"Best Hyperparameters:\")\n",
    "print(\"Criterion:\", criterion)\n",
    "print(\"Max Depth:\", max_depth)\n",
    "print(\"Max Features:\", max_features)\n",
    "print(\"Min Samples Leaf:\", min_samples_leaf)\n",
    "print(\"Min Samples Split:\", min_samples_split)\n",
    "print(\"N Estimators:\", n_estimators)\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "print(\"\\nAccuracy Score:\", accuracy)\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(class_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Read the grid search results from the text file\n",
    "df = pd.read_csv(\"C:\\\\Shanila\\\\CSE\\\\cse445\\\\final_project\\\\git_project\\\\Machine_Learning_Project\\\\sha\\\\result3\\\\grid_search_results.txt\", delimiter=\"\\t\", header=0)\n",
    "\n",
    "# Filter rows with 'criterion' equal to 'gini' and 'entropy'\n",
    "gini_df = df[df['param_criterion'] == 'gini']\n",
    "entropy_df = df[df['param_criterion'] == 'entropy']\n",
    "\n",
    "# Sort the data by 'param_n_estimators' for both Gini and Entropy\n",
    "gini_df = gini_df.sort_values(by='param_n_estimators')\n",
    "entropy_df = entropy_df.sort_values(by='param_n_estimators')\n",
    "\n",
    "# Extract the number of estimators and mean test scores\n",
    "gini_n_estimators = gini_df['param_n_estimators']\n",
    "gini_mean_test_score = gini_df['mean_test_score']\n",
    "\n",
    "entropy_n_estimators = entropy_df['param_n_estimators']\n",
    "entropy_mean_test_score = entropy_df['mean_test_score']\n",
    "\n",
    "# Create a colorful line graph to compare Gini and Entropy\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(gini_n_estimators, gini_mean_test_score, label='Gini', marker='o', color='blue')\n",
    "plt.plot(entropy_n_estimators, entropy_mean_test_score, label='Entropy', marker='o', color='orange')\n",
    "\n",
    "# Set labels and title\n",
    "plt.xlabel('Number of Estimators')\n",
    "plt.ylabel('Mean Test Score')\n",
    "plt.title('Comparison of Gini and Entropy in Grid Search')\n",
    "plt.legend()\n",
    "\n",
    "# Save the graph as an image\n",
    "save_path = \"C:\\\\Shanila\\\\CSE\\\\cse445\\\\final_project\\\\git_project\\\\Machine_Learning_Project\\\\sha\\\\result2\\\\grid_search_comparison.png\"\n",
    "plt.savefig(save_path, bbox_inches='tight')\n",
    "\n",
    "# Show the graph (optional)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae99c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae3c205",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_grid=grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef53df81",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c491691c",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_grid.fit(X_train, y_train)\n",
    "y_pred=best_grid.predict(X_test)\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(\"Accuracy Score {}\".format(accuracy_score(y_test,y_pred)))\n",
    "print(\"Classification report: {}\".format(classification_report(y_test,y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f0324b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "trial = study.best_trial\n",
    "\n",
    "print('Accuracy: {}'.format(trial.value))\n",
    "print(\"Best hyperparameters: {}\".format(trial.params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc5c7f4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "\n",
    "# Load the results from the specified file\n",
    "results_file = r'C:\\Shanila\\CSE\\cse445\\final_project\\git_project\\Machine_Learning_Project\\sha\\result3\\grid_search_results.txt'\n",
    "\n",
    "with open(results_file, 'r') as file:\n",
    "    results_data = file.read()\n",
    "\n",
    "# Split the data into Gini and Entropy sections based on a delimiter\n",
    "delimiter = \"####################\"  # Adjust this delimiter as per your file structure\n",
    "sections = results_data.split(delimiter)\n",
    "\n",
    "# Ensure both Gini and Entropy sections are present\n",
    "if len(sections) != 2:\n",
    "    print(\"Both Gini and Entropy sections are not found in the file.\")\n",
    "else:\n",
    "    gini_section, entropy_section = sections\n",
    "\n",
    "    # Extract and process Gini and Entropy results\n",
    "    def process_results(section):\n",
    "        lines = section.strip().split('\\n')[1:]  # Skip the header line\n",
    "        results = {}\n",
    "        for line in lines:\n",
    "            parts = line.split()\n",
    "            param_name = parts[0][:-1]\n",
    "            param_value = float(parts[1])\n",
    "            results[param_name] = param_value\n",
    "        return results\n",
    "\n",
    "    gini_results = process_results(gini_section)\n",
    "    entropy_results = process_results(entropy_section)\n",
    "\n",
    "    # Compare the results\n",
    "    comparison = {}\n",
    "    for param_name in gini_results:\n",
    "        gini_value = gini_results[param_name]\n",
    "        entropy_value = entropy_results[param_name]\n",
    "        comparison[param_name] = {\n",
    "            'Gini': gini_value,\n",
    "            'Entropy': entropy_value,\n",
    "            'Difference': gini_value - entropy_value\n",
    "        }\n",
    "\n",
    "    # Save the comparison to a text file\n",
    "    output_file = r'C:\\Shanila\\CSE\\cse445\\final_project\\git_project\\Machine_Learning_Project\\sha\\result2\\comparison.txt'\n",
    "    with open(output_file, 'w') as file:\n",
    "        file.write(\"Parameter  Gini  Entropy  Difference\\n\")\n",
    "        for param_name, values in comparison.items():\n",
    "            file.write(f\"{param_name}: {values['Gini']} {values['Entropy']} {values['Difference']}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9db24dd",
   "metadata": {},
   "source": [
    "# KNeighborsClassifier() results in highest train and test accuracy(99.7%)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58fe9492",
   "metadata": {},
   "source": [
    "# LIME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee88e72c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Use Lime for XAI\n",
    "import lime\n",
    "import lime.lime_tabular\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6535dd7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cddadec",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = lime.lime_tabular.LimeTabularExplainer(training_data = X_train.values, mode = 'classification',\n",
    "                                                   feature_names = X_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "986adc84",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "exp = explainer.explain_instance(X_test.iloc[0], knn.predict_proba)\n",
    "exp.show_in_notebook(show_table = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7cf8007",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_fig(\"lime analysis\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Shanila\\CSE\\cse445\\final_project\\git_project\\Machine_Learning_Project\\sha\\sunaira.ipynb Cell 73\u001b[0m line \u001b[0;36m7\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Shanila/CSE/cse445/final_project/git_project/Machine_Learning_Project/sha/sunaira.ipynb#Y132sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Shanila/CSE/cse445/final_project/git_project/Machine_Learning_Project/sha/sunaira.ipynb#Y132sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m# Create an explainer\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Shanila/CSE/cse445/final_project/git_project/Machine_Learning_Project/sha/sunaira.ipynb#Y132sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m explainer \u001b[39m=\u001b[39m lime\u001b[39m.\u001b[39mlime_tabular\u001b[39m.\u001b[39mLimeTabularExplainer(training_data\u001b[39m=\u001b[39mX_train\u001b[39m.\u001b[39mvalues, mode\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mclassification\u001b[39m\u001b[39m'\u001b[39m, feature_names\u001b[39m=\u001b[39mX_train\u001b[39m.\u001b[39mcolumns)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Shanila/CSE/cse445/final_project/git_project/Machine_Learning_Project/sha/sunaira.ipynb#Y132sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39m# Explain the prediction for the first instance in your test data\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Shanila/CSE/cse445/final_project/git_project/Machine_Learning_Project/sha/sunaira.ipynb#Y132sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m explanation \u001b[39m=\u001b[39m explainer\u001b[39m.\u001b[39mexplain_instance(X_test\u001b[39m.\u001b[39miloc[\u001b[39m0\u001b[39m], knn\u001b[39m.\u001b[39mpredict_proba, num_features\u001b[39m=\u001b[39m\u001b[39mlen\u001b[39m(X_train\u001b[39m.\u001b[39mcolumns))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "# save image\n",
    "\n",
    "import lime\n",
    "import lime.lime_tabular\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Create an explainer\n",
    "explainer = lime.lime_tabular.LimeTabularExplainer(training_data=X_train.values, mode='classification', feature_names=X_train.columns)\n",
    "\n",
    "# Explain the prediction for the first instance in your test data\n",
    "explanation = explainer.explain_instance(X_test.iloc[0], knn.predict_proba, num_features=len(X_train.columns))\n",
    "\n",
    "# Show the explanation with a table\n",
    "explanation.show_in_notebook(show_table=True)\n",
    "\n",
    "# Save the explanation as an HD PNG\n",
    "fig = explanation.as_pyplot_figure()\n",
    "save_path = r'C:\\Shanila\\CSE\\cse445\\final_project\\git_project\\Machine_Learning_Project\\sha\\result4\\lime_explanation_hd.png'\n",
    "fig.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "plt.close(fig)  # Close the figure to avoid displaying it\n",
    "\n",
    "# Display the first few rows of your test data\n",
    "X_test.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "405c83d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1500101a",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.as_pyplot_figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "518140b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_fig(\"lime figure analysis\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25acc796",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
